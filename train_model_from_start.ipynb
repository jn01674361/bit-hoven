{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "import pickle\n",
    "import keras \n",
    "import numpy\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train_network():\n",
    "#     notes = get_notes()\n",
    "#     n_vocab = len(set(notes))\n",
    "    \n",
    "#     network_input, network_output = prepare_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    sequence_length = 100   #det här kan vi gärna ändra\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    note_to_int = dict((note,number) for number,note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    for i in range(0,len(notes)-sequence_length,1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i+sequence_length]\n",
    "        \n",
    "        network_input.append([note_to_int[char] for char in sequence_in ])\n",
    "        \n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length,1))\n",
    "    \n",
    "    network_input = network_input /float(n_vocab)\n",
    "    \n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    \n",
    "    return(network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    notes=[]\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = None\n",
    "        \n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "\n",
    "\n",
    "\n",
    "        if parts:\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            #den ena är accord, t.ex. B5, den andra är siffror, t.ex 11.2\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                #print('.'.join(str(n) for n in element.normalOrder))\n",
    "                \n",
    "\n",
    "        with open('data/notes','wb') as filepath:\n",
    "            pickle.dump(notes, filepath)\n",
    "            \n",
    "    return notes\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512,input_shape=(network_input.shape[1],network_input.shape[2]),return_sequences=True))    \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,network_input,network_output):\n",
    "    filepath = \"weights-improvement-{epoch:02d}--{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor = 'loss',\n",
    "        verbose = 0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=10,batch_size = 64, callbacks=callbacks_list)\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "159/159 [==============================] - 23s 143ms/step - loss: 4.3173\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 15s 93ms/step - loss: 5.4414\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 14s 91ms/step - loss: 3.4582\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 15s 91ms/step - loss: 3.4474\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 15s 91ms/step - loss: 3.2975\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 15s 91ms/step - loss: 3.2783\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 15s 91ms/step - loss: 3.2775\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 15s 95ms/step - loss: 3.2678\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 15s 92ms/step - loss: 3.2402\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 15s 92ms/step - loss: 3.2407\n"
     ]
    }
   ],
   "source": [
    "notes = get_notes()\n",
    "n_vocab = len(set(notes))\n",
    "network_input,network_output = prepare_sequences(notes,n_vocab)\n",
    "\n",
    "model = create_network(network_input,n_vocab)\n",
    "train(model,network_input,network_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
